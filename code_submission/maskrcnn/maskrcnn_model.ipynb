{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8adbb978-5c1e-4898-ac58-f52c1487ea06",
   "metadata": {},
   "source": [
    "# 1. Import Libraries and Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799cdfb3-8328-4083-8e03-126af51ec7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import skimage.draw\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from multiprocessing import freeze_support\n",
    "from google.cloud import storage\n",
    "from IPython.display import Image\n",
    "\n",
    "# Import mask rcnn code framework\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn.config import Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61281e86-a797-433b-a24a-60ec6e6c2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer training and validation data files from Cloud Bucket to local storage in VM instance \n",
    "# DON'T NEED TO RUN THIS MORE THAN ONCE!\n",
    "\n",
    "# client = storage.Client()\n",
    "# DATA_BUCKET = 'w207-final-project'\n",
    "# databucket = client.get_bucket(DATA_BUCKET)\n",
    "# datafiles = databucket.list_blobs()\n",
    "\n",
    "# Transfer Training Files\n",
    "# files=[a.name for a in datafiles if a.name.startswith('train_clean')]\n",
    "\n",
    "# Transfer Validation Files\n",
    "# files=[a.name for a in datafiles if a.name.startswith('val_clean')]\n",
    "\n",
    "# Transfer Validation Masks\n",
    "# files=[a.name for a in datafiles if a.name.endswith('png')]\n",
    "\n",
    "# print(files)\n",
    "# Copy files from bucket into local folder\n",
    "# for file in files:\n",
    "#     blob = databucket.get_blob(file)\n",
    "#     blob.download_to_filename(file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409fee18-cb0c-446d-80a3-413b3f5353b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train image files: 3220\n",
      "val image files: 359\n",
      "val image mask files: 357\n"
     ]
    }
   ],
   "source": [
    "# Check if all files are copied over\n",
    "list = os.listdir('train_clean') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print(\"# train image files:\", number_files)\n",
    "list = os.listdir('val_clean') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print(\"val image files:\", number_files)\n",
    "list = os.listdir('val_clean_masks') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print(\"val image mask files:\", number_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ee70f-ee61-4457-9a11-e5000ba4f8cc",
   "metadata": {},
   "source": [
    "# 2. Set Up Model Training \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883c36d-3e8c-4b57-bb44-6641e6fa3d6e",
   "metadata": {},
   "source": [
    "## a. Set file directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d9853d-ff4f-460e-a716-69bd3e361443",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(\"\")\n",
    "\n",
    "# Path to trained weights file\n",
    "\n",
    "# Original weights path (run this during first iteration)\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# New weights path (provide updated path to weights from generated models here)\n",
    "WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_object_0100.h5\")\n",
    "\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3096f26-a85e-4331-b0a4-0fd5b8d415c4",
   "metadata": {},
   "source": [
    "## b. Define classes for model configuration and loading images for training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ed1939-9a44-49d6-8732-0ac39a2bed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomConfig(Config):\n",
    "    \"\"\"Configuration for training on the custom  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"object\"\n",
    "\n",
    "    # We are using the NVIDIA T4 Tensore Core GPU, which has 16GB memory.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + drivable area\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 2\n",
    "\n",
    "    # Number of validation steps to run at the end of every training epoch.\n",
    "    # A bigger number improves accuracy of validation stats, but slows\n",
    "    # down the training.\n",
    "    VALIDATION_STEPS = 10\n",
    "    \n",
    "    # Backgone architecture supported values are: resnet50, resnet101.\n",
    "    # You can also provide a callable that should have the signature\n",
    "    # of model.resnet_graph. If you do so, you need to supply a callable\n",
    "    # to COMPUTE_BACKBONE_SHAPE as well\n",
    "    BACKBONE = \"resnet101\" # Default\n",
    "    # BACKBONE = \"resnet50\"\n",
    "\n",
    "    # Skip detections below % confidence specified\n",
    "    # DETECTION_MIN_CONFIDENCE = 0.5\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ea7f8f5-ab73-4375-b03a-a6c4b965ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and validation images\n",
    "class CustomDataset(utils.Dataset):\n",
    "\n",
    "    def load_custom(self, dataset_dir, subset):\n",
    "\n",
    "        \"\"\"Load a subset of the driving dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "\n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"object\", 1, \"drivable area\")\n",
    "        \n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset + \"_clean\")\n",
    "\n",
    "        # Set labels to appropriate image file names (training or validation)\n",
    "        if subset == 'train':\n",
    "            labels = train_labels_cleaned\n",
    "        else:\n",
    "            labels = val_labels_cleaned\n",
    "        \n",
    "        # Given an image, get all the items that are considered drivable area\n",
    "        # For each item, save the x and y vertices into two lists, x and y\n",
    "        for index, image in labels.iterrows():\n",
    "\n",
    "            polygons = []\n",
    "            objects = []\n",
    "            for obj in image['labels']:\n",
    "                x = []\n",
    "                y = []\n",
    "                if obj['category'] == 'drivable area':\n",
    "                    for coord in obj['poly2d'][0]['vertices']:\n",
    "                        coord = [round(num) for num in coord]\n",
    "                        # Set max value of coordinates (max x is 1280, max y is 720)\n",
    "                        if coord[0] >= 1280:\n",
    "                            x.append(1279)\n",
    "                        else:\n",
    "                            x.append(coord[0])\n",
    "                        if coord[1] >= 720:\n",
    "                            y.append(719)\n",
    "                        else:\n",
    "                            y.append(coord[1])\n",
    "                    polygons.append({'name': 'polygon',\n",
    "                                      'all_points_x': x,\n",
    "                                      'all_points_y': y})\n",
    "                    objects.append('drivable area')\n",
    "                    \n",
    "            image_path = os.path.join(dataset_dir, image['name'])\n",
    "\n",
    "            # Set dictionary of names and ID for different object classes other than background\n",
    "            name_dict = {\"drivable area\": 1}\n",
    "            \n",
    "            num_ids = [name_dict[a] for a in objects]\n",
    "\n",
    "            self.add_image(\n",
    "                \"object\",  ## for a single class just add the name here\n",
    "                image_id=image['name'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=1280, height=720,\n",
    "                polygons=polygons,\n",
    "                num_ids=num_ids\n",
    "                )\n",
    "        return\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "        num_ids = info['num_ids']\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "        \trr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "\n",
    "        \tmask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        # Map class names to class IDs.\n",
    "        num_ids = np.array(num_ids, dtype=np.int32)\n",
    "        return mask, num_ids #np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"object\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afdb972a-5fdc-42e5-9524-0a3f981d5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = CustomDataset()\n",
    "    dataset_train.load_custom(ROOT_DIR, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = CustomDataset()\n",
    "    dataset_val.load_custom(ROOT_DIR, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    print(\"Training network heads\")\n",
    "\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=40, # Tune this hyperparameter\n",
    "                layers='heads')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f672fb47-49cd-46a0-83a7-7b9be68808e9",
   "metadata": {},
   "source": [
    "## c. Load object labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5461756e-b738-4581-93af-da9a93bc3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON files for image segment labels\n",
    "\n",
    "with open('train_clean/bdd100k_labels_images_train.json') as json_file:\n",
    "    train_labels = json.load(json_file)\n",
    "\n",
    "with open('val_clean/bdd100k_labels_images_val.json') as json_file:\n",
    "    val_labels = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1340050e-554a-4897-b725-2f5b10b14b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# REQUIRED: Normalize semi-structured JSON data into a pd dataframe\n",
    "# Note that train_labels json file contains both labels for training and validation set \n",
    "train_labels_normalized = pd.json_normalize(train_labels)\n",
    "\n",
    "train_filenames = []\n",
    "val_filenames = []\n",
    "\n",
    "# REMEMBER TO REPLACE AFTER INITIAL TESTING\n",
    "for myfile in os.listdir(ROOT_DIR + \"/train_clean\"):\n",
    "    if myfile.endswith(\".jpg\"):\n",
    "        train_filenames.append(os.path.join(myfile))\n",
    "\n",
    "for myfile in os.listdir(ROOT_DIR + \"/val_clean\"):\n",
    "    if myfile.endswith(\".jpg\"):\n",
    "        val_filenames.append(os.path.join(myfile))\n",
    "\n",
    "# Save labels for only the images within the folder contents\n",
    "train_labels_cleaned = train_labels_normalized.loc[train_labels_normalized['name'].isin(train_filenames)]\n",
    "\n",
    "# val_labels_split\n",
    "val_labels_cleaned = train_labels_normalized.loc[train_labels_normalized['name'].isin(val_filenames)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75605acf-c414-42e4-8aff-2bc525de1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ONLY: Verify image sizes and dimensions\n",
    "\n",
    "# from PIL import Image as im\n",
    "\n",
    "# image_folder = 'train_clean/'\n",
    "\n",
    "# for filename in train_filenames:\n",
    "\n",
    "#     with im.open(image_folder + filename) as image:\n",
    "#         # convert image to numpy array\n",
    "#         # plt.imshow(image)\n",
    "#         image_data = np.asarray(image)\n",
    "#     if image_data.shape != (720, 1280, 3):\n",
    "#         print(\"Image Shape for \" + filename + \" is \" + image_data)\n",
    "\n",
    "# image_folder = 'val_clean/'\n",
    "\n",
    "# for filename in val_filenames:\n",
    "\n",
    "#     with im.open(image_folder + filename) as image:\n",
    "#         # convert image to numpy array\n",
    "#         # plt.imshow(image)\n",
    "#         image_data = np.asarray(image)\n",
    "#     if image_data.shape != (720, 1280, 3):\n",
    "#         print(\"Image Shape for \" + filename + \" is \" + image_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b656c8-2699-46de-a844-203374de01d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39082542-e41d-4e38-b854-64ee31cea6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c15549a-320a-40d4-84b7-9220d356d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = CustomConfig()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=DEFAULT_LOGS_DIR)\n",
    "\n",
    "# weights_path = COCO_WEIGHTS_PATH # For first run only\n",
    "weights_path = WEIGHTS_PATH\n",
    "        # Download weights file\n",
    "if not os.path.exists(weights_path):\n",
    "  utils.download_trained_weights(weights_path)\n",
    "\n",
    "model.load_weights(weights_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f07158e8-dfaa-48a8-b629-f89c1abcf62f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/jupyter/logs/object20220412T1819/mask_rcnn_object_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "2022-04-12 18:19:33.857004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:19:33.857480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:19:33.857799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:19:33.858420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:19:33.858816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:19:33.859132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13823 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/GatherV2_2:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/GatherV2_5:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/GatherV2_8:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/GatherV2_11:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/ROI_1/GatherV2_1_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/ROI_1/GatherV2_1_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/ROI_1/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "2022-04-12 18:20:35.117622: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -540 } dim { size: 56 } dim { size: 56 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -25 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -25 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -25 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "2022-04-12 18:20:35.120638: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -130 } dim { size: -131 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -36 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:35.120773: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -130 } dim { size: -131 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -36 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:35.120889: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -138 } dim { size: -139 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -39 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -39 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -39 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:35.120982: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -138 } dim { size: -139 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -39 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -39 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -39 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:35.121107: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -146 } dim { size: -147 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -41 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:35.121287: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -146 } dim { size: -147 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -41 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:35.121434: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -122 } dim { size: -123 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -43 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -43 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -43 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:35.121530: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -122 } dim { size: -123 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -43 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -43 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -43 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:36.862817: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 17s - batch: 0.0000e+00 - size: 1.0000 - loss: 29.9578 - rpn_class_loss: 21.8579 - rpn_bbox_loss: 8.0989 - mrcnn_class_loss: 0.0010 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 18:20:48.062987: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-04-12 18:20:48.063032: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-04-12 18:20:48.063087: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\n",
      "2022-04-12 18:20:48.064073: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-04-12 18:20:49.083697: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-04-12 18:20:49.084316: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n",
      "2022-04-12 18:20:49.154177: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 2438 callback api events and 2437 activity events. \n",
      "2022-04-12 18:20:49.211831: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-04-12 18:20:49.283388: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /home/jupyter/logs/object20220412T1819/plugins/profile/2022_04_12_18_20_49\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - batch: 0.5000 - size: 1.0000 - loss: 23.7647 - rpn_class_loss: 16.4438 - rpn_bbox_loss: 7.3203 - mrcnn_class_loss: 5.2014e-04 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 18:20:49.332143: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to /home/jupyter/logs/object20220412T1819/plugins/profile/2022_04_12_18_20_49/w207-final-project-2.trace.json.gz\n",
      "2022-04-12 18:20:49.434986: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /home/jupyter/logs/object20220412T1819/plugins/profile/2022_04_12_18_20_49\n",
      "\n",
      "2022-04-12 18:20:49.444072: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to /home/jupyter/logs/object20220412T1819/plugins/profile/2022_04_12_18_20_49/w207-final-project-2.memory_profile.json.gz\n",
      "2022-04-12 18:20:49.447775: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /home/jupyter/logs/object20220412T1819/plugins/profile/2022_04_12_18_20_49\n",
      "Dumped tool data for xplane.pb to /home/jupyter/logs/object20220412T1819/plugins/profile/2022_04_12_18_20_49/w207-final-project-2.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /home/jupyter/logs/object20220412T1819/plugins/profile/2022_04_12_18_20_49/w207-final-project-2.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /home/jupyter/logs/object20220412T1819/plugins/profile/2022_04_12_18_20_49/w207-final-project-2.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /home/jupyter/logs/object20220412T1819/plugins/profile/2022_04_12_18_20_49/w207-final-project-2.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /home/jupyter/logs/object20220412T1819/plugins/profile/2022_04_12_18_20_49/w207-final-project-2.kernel_stats.pb\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2022-04-12 18:20:54.318645: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -395 } dim { size: 56 } dim { size: 56 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -12 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -12 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -12 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "2022-04-12 18:20:54.323798: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -324 } dim { size: -325 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -23 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -23 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -23 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:54.324664: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -324 } dim { size: -325 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -23 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -23 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -23 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:54.325322: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -314 } dim { size: -315 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -26 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:54.325957: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -314 } dim { size: -315 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -26 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:54.326577: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -302 } dim { size: -303 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -28 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -28 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -28 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:54.327226: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -302 } dim { size: -303 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -28 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -28 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -28 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:54.327919: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -288 } dim { size: -289 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -30 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-12 18:20:54.328572: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -288 } dim { size: -289 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -30 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14495252480 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 62s 44s/step - batch: 0.5000 - size: 1.0000 - loss: 23.7647 - rpn_class_loss: 16.4438 - rpn_bbox_loss: 7.3203 - mrcnn_class_loss: 5.2014e-04 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 5.1008 - val_rpn_class_loss: 2.1336 - val_rpn_bbox_loss: 2.9672 - val_mrcnn_class_loss: 2.3842e-07 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 8s 7s/step - batch: 0.5000 - size: 1.0000 - loss: 7.0294 - rpn_class_loss: 1.2848 - rpn_bbox_loss: 3.3471 - mrcnn_class_loss: 0.2656 - mrcnn_bbox_loss: 1.6785 - mrcnn_mask_loss: 0.4533 - val_loss: 7.6435 - val_rpn_class_loss: 0.2933 - val_rpn_bbox_loss: 5.2483 - val_mrcnn_class_loss: 0.0505 - val_mrcnn_bbox_loss: 1.1178 - val_mrcnn_mask_loss: 0.9336\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 8s 8s/step - batch: 0.5000 - size: 1.0000 - loss: 5.2803 - rpn_class_loss: 0.1597 - rpn_bbox_loss: 4.4664 - mrcnn_class_loss: 0.0092 - mrcnn_bbox_loss: 0.2473 - mrcnn_mask_loss: 0.3976 - val_loss: 12.2693 - val_rpn_class_loss: 0.1372 - val_rpn_bbox_loss: 12.1321 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 5.2998 - rpn_class_loss: 0.0726 - rpn_bbox_loss: 5.2272 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 12.7127 - val_rpn_class_loss: 0.0621 - val_rpn_bbox_loss: 12.6507 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 11.9606 - rpn_class_loss: 0.1307 - rpn_bbox_loss: 9.1608 - mrcnn_class_loss: 0.1006 - mrcnn_bbox_loss: 1.8259 - mrcnn_mask_loss: 0.7425 - val_loss: 11.0137 - val_rpn_class_loss: 0.1537 - val_rpn_bbox_loss: 8.1159 - val_mrcnn_class_loss: 0.0220 - val_mrcnn_bbox_loss: 2.4881 - val_mrcnn_mask_loss: 0.2340\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 7.4548 - rpn_class_loss: 0.1309 - rpn_bbox_loss: 5.0531 - mrcnn_class_loss: 0.0231 - mrcnn_bbox_loss: 1.9064 - mrcnn_mask_loss: 0.3413 - val_loss: 35.2712 - val_rpn_class_loss: 0.0409 - val_rpn_bbox_loss: 4.4375 - val_mrcnn_class_loss: 0.8177 - val_mrcnn_bbox_loss: 28.2221 - val_mrcnn_mask_loss: 1.7530\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 10s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 7.8959 - rpn_class_loss: 0.0216 - rpn_bbox_loss: 2.9575 - mrcnn_class_loss: 0.1132 - mrcnn_bbox_loss: 4.1437 - mrcnn_mask_loss: 0.6599 - val_loss: 29.8714 - val_rpn_class_loss: 0.0203 - val_rpn_bbox_loss: 1.7095 - val_mrcnn_class_loss: 1.6522 - val_mrcnn_bbox_loss: 24.9561 - val_mrcnn_mask_loss: 1.5332\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 4.7635 - rpn_class_loss: 1.2187e-04 - rpn_bbox_loss: 1.7031 - mrcnn_class_loss: 0.0612 - mrcnn_bbox_loss: 2.3617 - mrcnn_mask_loss: 0.6374 - val_loss: 41.1809 - val_rpn_class_loss: 0.0677 - val_rpn_bbox_loss: 5.1949 - val_mrcnn_class_loss: 0.4420 - val_mrcnn_bbox_loss: 33.4712 - val_mrcnn_mask_loss: 2.0052\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 19.5246 - rpn_class_loss: 0.0534 - rpn_bbox_loss: 2.6033 - mrcnn_class_loss: 0.0890 - mrcnn_bbox_loss: 15.8099 - mrcnn_mask_loss: 0.9690 - val_loss: 8.2035 - val_rpn_class_loss: 0.0848 - val_rpn_bbox_loss: 6.3232 - val_mrcnn_class_loss: 0.0260 - val_mrcnn_bbox_loss: 1.6347 - val_mrcnn_mask_loss: 0.1348\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 9s 8s/step - batch: 0.5000 - size: 1.0000 - loss: 8.9359 - rpn_class_loss: 0.0562 - rpn_bbox_loss: 2.1586 - mrcnn_class_loss: 0.1671 - mrcnn_bbox_loss: 6.2005 - mrcnn_mask_loss: 0.3535 - val_loss: 6.8999 - val_rpn_class_loss: 0.0784 - val_rpn_bbox_loss: 5.3038 - val_mrcnn_class_loss: 0.0025 - val_mrcnn_bbox_loss: 1.3985 - val_mrcnn_mask_loss: 0.1168\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 9.0082 - rpn_class_loss: 0.0510 - rpn_bbox_loss: 1.7744 - mrcnn_class_loss: 0.1056 - mrcnn_bbox_loss: 6.4354 - mrcnn_mask_loss: 0.6417 - val_loss: 7.3145 - val_rpn_class_loss: 0.0381 - val_rpn_bbox_loss: 5.7572 - val_mrcnn_class_loss: 0.0046 - val_mrcnn_bbox_loss: 1.3981 - val_mrcnn_mask_loss: 0.1166\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 11.0596 - rpn_class_loss: 0.0290 - rpn_bbox_loss: 3.4429 - mrcnn_class_loss: 8.2520e-04 - mrcnn_bbox_loss: 6.9891 - mrcnn_mask_loss: 0.5977 - val_loss: 7.7415 - val_rpn_class_loss: 0.0162 - val_rpn_bbox_loss: 6.2263 - val_mrcnn_class_loss: 0.0064 - val_mrcnn_bbox_loss: 1.3750 - val_mrcnn_mask_loss: 0.1176\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 10.3484 - rpn_class_loss: 4.8585e-05 - rpn_bbox_loss: 4.1178 - mrcnn_class_loss: 0.1321 - mrcnn_bbox_loss: 5.5194 - mrcnn_mask_loss: 0.5791 - val_loss: 7.3369 - val_rpn_class_loss: 0.0151 - val_rpn_bbox_loss: 7.3218 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 5.8033 - rpn_class_loss: 1.7699e-04 - rpn_bbox_loss: 2.3480 - mrcnn_class_loss: 0.0480 - mrcnn_bbox_loss: 2.8532 - mrcnn_mask_loss: 0.5539 - val_loss: 13.7179 - val_rpn_class_loss: 0.0329 - val_rpn_bbox_loss: 7.5633 - val_mrcnn_class_loss: 0.0074 - val_mrcnn_bbox_loss: 4.3433 - val_mrcnn_mask_loss: 1.7711\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 2.1528 - rpn_class_loss: 5.1921e-04 - rpn_bbox_loss: 2.1523 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 7.0268 - val_rpn_class_loss: 0.0911 - val_rpn_bbox_loss: 6.9357 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 1.3557 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 1.3533 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 12.7347 - val_rpn_class_loss: 0.2174 - val_rpn_bbox_loss: 4.9799 - val_mrcnn_class_loss: 0.0436 - val_mrcnn_bbox_loss: 5.9451 - val_mrcnn_mask_loss: 1.5488\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 5.2252 - rpn_class_loss: 0.0781 - rpn_bbox_loss: 1.7596 - mrcnn_class_loss: 0.0194 - mrcnn_bbox_loss: 2.4888 - mrcnn_mask_loss: 0.8793 - val_loss: 13.1888 - val_rpn_class_loss: 0.1854 - val_rpn_bbox_loss: 4.7694 - val_mrcnn_class_loss: 0.1418 - val_mrcnn_bbox_loss: 6.0794 - val_mrcnn_mask_loss: 2.0127\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 4.6789 - rpn_class_loss: 0.0338 - rpn_bbox_loss: 2.3208 - mrcnn_class_loss: 0.0149 - mrcnn_bbox_loss: 1.6305 - mrcnn_mask_loss: 0.6788 - val_loss: 10.6376 - val_rpn_class_loss: 0.0351 - val_rpn_bbox_loss: 10.1050 - val_mrcnn_class_loss: 0.0048 - val_mrcnn_bbox_loss: 0.3550 - val_mrcnn_mask_loss: 0.1378\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 6.7342 - rpn_class_loss: 0.0051 - rpn_bbox_loss: 4.4228 - mrcnn_class_loss: 0.0059 - mrcnn_bbox_loss: 1.7045 - mrcnn_mask_loss: 0.5961 - val_loss: 13.4262 - val_rpn_class_loss: 0.0550 - val_rpn_bbox_loss: 13.3712 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 4.6106 - rpn_class_loss: 8.4622e-04 - rpn_bbox_loss: 4.6098 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 10.6790 - val_rpn_class_loss: 0.0673 - val_rpn_bbox_loss: 10.6117 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 9s 8s/step - batch: 0.5000 - size: 1.0000 - loss: 9.4841 - rpn_class_loss: 0.0759 - rpn_bbox_loss: 4.1718 - mrcnn_class_loss: 0.0082 - mrcnn_bbox_loss: 4.5086 - mrcnn_mask_loss: 0.7196 - val_loss: 8.3846 - val_rpn_class_loss: 0.0413 - val_rpn_bbox_loss: 8.3432 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 3.8189 - rpn_class_loss: 0.0258 - rpn_bbox_loss: 2.5003 - mrcnn_class_loss: 0.0014 - mrcnn_bbox_loss: 1.0009 - mrcnn_mask_loss: 0.2905 - val_loss: 9.9601 - val_rpn_class_loss: 0.0645 - val_rpn_bbox_loss: 4.3357 - val_mrcnn_class_loss: 0.9281 - val_mrcnn_bbox_loss: 3.8327 - val_mrcnn_mask_loss: 0.7991\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 4.1217 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 1.3473 - mrcnn_class_loss: 0.0304 - mrcnn_bbox_loss: 2.1206 - mrcnn_mask_loss: 0.6207 - val_loss: 4.1666 - val_rpn_class_loss: 0.0738 - val_rpn_bbox_loss: 3.8229 - val_mrcnn_class_loss: 0.0018 - val_mrcnn_bbox_loss: 0.1356 - val_mrcnn_mask_loss: 0.1326\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 4.9217 - rpn_class_loss: 0.0031 - rpn_bbox_loss: 3.0157 - mrcnn_class_loss: 0.0069 - mrcnn_bbox_loss: 1.2760 - mrcnn_mask_loss: 0.6200 - val_loss: 5.8574 - val_rpn_class_loss: 0.0431 - val_rpn_bbox_loss: 4.9311 - val_mrcnn_class_loss: 0.0106 - val_mrcnn_bbox_loss: 0.7266 - val_mrcnn_mask_loss: 0.1459\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 18.5381 - rpn_class_loss: 0.8459 - rpn_bbox_loss: 15.5732 - mrcnn_class_loss: 0.0568 - mrcnn_bbox_loss: 1.6783 - mrcnn_mask_loss: 0.3838 - val_loss: 4.5611 - val_rpn_class_loss: 0.0290 - val_rpn_bbox_loss: 4.5321 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 13.8055 - rpn_class_loss: 0.5376 - rpn_bbox_loss: 10.7802 - mrcnn_class_loss: 0.0582 - mrcnn_bbox_loss: 2.1105 - mrcnn_mask_loss: 0.3191 - val_loss: 8.0306 - val_rpn_class_loss: 0.0640 - val_rpn_bbox_loss: 4.5045 - val_mrcnn_class_loss: 0.1413 - val_mrcnn_bbox_loss: 2.7967 - val_mrcnn_mask_loss: 0.5241\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 10s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 9.9934 - rpn_class_loss: 0.2441 - rpn_bbox_loss: 6.3577 - mrcnn_class_loss: 0.1276 - mrcnn_bbox_loss: 2.9358 - mrcnn_mask_loss: 0.3281 - val_loss: 7.8691 - val_rpn_class_loss: 0.5626 - val_rpn_bbox_loss: 3.1149 - val_mrcnn_class_loss: 0.4458 - val_mrcnn_bbox_loss: 2.9829 - val_mrcnn_mask_loss: 0.7630\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 5.6148 - rpn_class_loss: 0.4004 - rpn_bbox_loss: 3.3957 - mrcnn_class_loss: 0.2255 - mrcnn_bbox_loss: 1.2283 - mrcnn_mask_loss: 0.3650 - val_loss: 3.1116 - val_rpn_class_loss: 0.5123 - val_rpn_bbox_loss: 2.5993 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 10.7774 - rpn_class_loss: 3.1327 - rpn_bbox_loss: 5.8960 - mrcnn_class_loss: 0.0932 - mrcnn_bbox_loss: 1.3326 - mrcnn_mask_loss: 0.3229 - val_loss: 7.6281 - val_rpn_class_loss: 0.1390 - val_rpn_bbox_loss: 3.7534 - val_mrcnn_class_loss: 0.0583 - val_mrcnn_bbox_loss: 3.0309 - val_mrcnn_mask_loss: 0.6466\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 6.4478 - rpn_class_loss: 1.6448 - rpn_bbox_loss: 2.9472 - mrcnn_class_loss: 0.1773 - mrcnn_bbox_loss: 1.0700 - mrcnn_mask_loss: 0.6086 - val_loss: 4.9766 - val_rpn_class_loss: 0.2027 - val_rpn_bbox_loss: 3.1043 - val_mrcnn_class_loss: 0.0116 - val_mrcnn_bbox_loss: 1.0882 - val_mrcnn_mask_loss: 0.5698\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 6.4095 - rpn_class_loss: 0.9467 - rpn_bbox_loss: 4.6679 - mrcnn_class_loss: 0.0526 - mrcnn_bbox_loss: 0.4424 - mrcnn_mask_loss: 0.3000 - val_loss: 4.2497 - val_rpn_class_loss: 3.1860 - val_rpn_bbox_loss: 1.0637 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 5.2159 - rpn_class_loss: 2.7464 - rpn_bbox_loss: 2.4695 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 2.7425 - val_rpn_class_loss: 1.2920 - val_rpn_bbox_loss: 1.4505 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 10.1218 - rpn_class_loss: 1.4605 - rpn_bbox_loss: 2.1885 - mrcnn_class_loss: 0.1738 - mrcnn_bbox_loss: 5.9743 - mrcnn_mask_loss: 0.3248 - val_loss: 11.3089 - val_rpn_class_loss: 0.1710 - val_rpn_bbox_loss: 2.0881 - val_mrcnn_class_loss: 0.4740 - val_mrcnn_bbox_loss: 7.8765 - val_mrcnn_mask_loss: 0.6993\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 9.6647 - rpn_class_loss: 0.4871 - rpn_bbox_loss: 2.6794 - mrcnn_class_loss: 0.2267 - mrcnn_bbox_loss: 5.6461 - mrcnn_mask_loss: 0.6254 - val_loss: 8.7676 - val_rpn_class_loss: 0.1661 - val_rpn_bbox_loss: 5.0228 - val_mrcnn_class_loss: 0.1041 - val_mrcnn_bbox_loss: 2.7845 - val_mrcnn_mask_loss: 0.6902\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 10.3604 - rpn_class_loss: 0.4287 - rpn_bbox_loss: 3.4814 - mrcnn_class_loss: 0.0380 - mrcnn_bbox_loss: 5.8144 - mrcnn_mask_loss: 0.5979 - val_loss: 9.9479 - val_rpn_class_loss: 0.1371 - val_rpn_bbox_loss: 5.1237 - val_mrcnn_class_loss: 0.0393 - val_mrcnn_bbox_loss: 4.1194 - val_mrcnn_mask_loss: 0.5283\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 10s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 10.6922 - rpn_class_loss: 0.1735 - rpn_bbox_loss: 2.8787 - mrcnn_class_loss: 0.0690 - mrcnn_bbox_loss: 6.9163 - mrcnn_mask_loss: 0.6548 - val_loss: 8.1520 - val_rpn_class_loss: 0.0856 - val_rpn_bbox_loss: 3.1547 - val_mrcnn_class_loss: 0.0242 - val_mrcnn_bbox_loss: 4.0873 - val_mrcnn_mask_loss: 0.8002\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 6.3329 - rpn_class_loss: 3.1403e-04 - rpn_bbox_loss: 3.2914 - mrcnn_class_loss: 0.0135 - mrcnn_bbox_loss: 2.4020 - mrcnn_mask_loss: 0.6257 - val_loss: 5.6744 - val_rpn_class_loss: 0.0382 - val_rpn_bbox_loss: 5.2129 - val_mrcnn_class_loss: 0.0078 - val_mrcnn_bbox_loss: 0.2680 - val_mrcnn_mask_loss: 0.1474\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 8s 8s/step - batch: 0.5000 - size: 1.0000 - loss: 5.3658 - rpn_class_loss: 0.0197 - rpn_bbox_loss: 4.3661 - mrcnn_class_loss: 0.0100 - mrcnn_bbox_loss: 0.6987 - mrcnn_mask_loss: 0.2713 - val_loss: 5.4407 - val_rpn_class_loss: 0.0384 - val_rpn_bbox_loss: 1.9313 - val_mrcnn_class_loss: 0.0591 - val_mrcnn_bbox_loss: 2.6063 - val_mrcnn_mask_loss: 0.8054\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 5.7775 - rpn_class_loss: 0.0182 - rpn_bbox_loss: 2.7742 - mrcnn_class_loss: 0.0020 - mrcnn_bbox_loss: 2.2517 - mrcnn_mask_loss: 0.7314 - val_loss: 5.2869 - val_rpn_class_loss: 0.0429 - val_rpn_bbox_loss: 4.7902 - val_mrcnn_class_loss: 1.4808e-04 - val_mrcnn_bbox_loss: 0.2919 - val_mrcnn_mask_loss: 0.1618\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 15.4538 - rpn_class_loss: 3.6260 - rpn_bbox_loss: 8.6632 - mrcnn_class_loss: 0.0272 - mrcnn_bbox_loss: 2.8042 - mrcnn_mask_loss: 0.3332 - val_loss: 7.7380 - val_rpn_class_loss: 0.0341 - val_rpn_bbox_loss: 7.0004 - val_mrcnn_class_loss: 0.0013 - val_mrcnn_bbox_loss: 0.5152 - val_mrcnn_mask_loss: 0.1870\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8156f82b-ecb6-40e3-b5a2-752268cbedef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
