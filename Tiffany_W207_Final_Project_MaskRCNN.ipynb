{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c00cac-93d3-448e-b63c-693bd9807f6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Adapted from https://www.youtube.com/watch?v=t1MrzuAUdoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da39123a-a748-4c38-b809-796c2ff0e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../Final_Project\")\n",
    "\n",
    "# Use leekunhee version to be compatible with tensorflow 2.x (https://github.com/leekunhee/Mask_RCNN)\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory to save logs and model checkpoints\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a7430ec-63f1-45d5-8e98-657923f04007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Directory: /Users/tiffanyshih/Documents/Coursework/MIDS_207/Final_Project\n",
      "Weights Path: /Users/tiffanyshih/Documents/Coursework/MIDS_207/Final_Project/mask_rcnn_coco.h5\n",
      "Logs Path: /Users/tiffanyshih/Documents/Coursework/MIDS_207/Final_Project/logs\n"
     ]
    }
   ],
   "source": [
    "# Check the directory paths\n",
    "print(\"Root Directory:\", ROOT_DIR)\n",
    "print(\"Weights Path:\", COCO_WEIGHTS_PATH)\n",
    "print(\"Logs Path:\", DEFAULT_LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c5ed91-707c-40b1-9c89-bcd6b652a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED: Load labels json file containing image object labels\n",
    "# Note: This will take awhile to load\n",
    "\n",
    "with open('train_clean/bdd100k_labels_images_train.json') as json_file:\n",
    "    train_labels = json.load(json_file)\n",
    "\n",
    "with open('val_clean/bdd100k_labels_images_val.json') as json_file:\n",
    "    test_labels = json.load(json_file)\n",
    "    \n",
    "#with open('val_clean/bdd100k_labels_images_test.json') as json_file:\n",
    "#    test_labels = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d0e72d8-3bf7-456d-97d9-d2231d679ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED: Normalize semi-structured JSON data into a pd dataframe\n",
    "train_labels_normalized = pd.json_normalize(train_labels)\n",
    "test_labels_normalized = pd.json_normalize(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f53135e-a4c8-4257-b4ea-38598340fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED: Function used to clean data, extract labels, and extract data for sunny, \n",
    "# highway, and daytime conditions\n",
    "\n",
    "def clean_data(labels_normalized):\n",
    "    # Initialize lists of object types. Each list will contain 69863 values, each of which corresponds to an image specified as a row in data_cleaned \n",
    "    num_objects = []\n",
    "    num_road = []\n",
    "    num_sidewalk = []\n",
    "    num_building = []\n",
    "    num_wall = []\n",
    "    num_fence = []\n",
    "    num_pole = []\n",
    "    num_traffic_light = []\n",
    "    num_traffic_sign = []\n",
    "    num_vegetation = []\n",
    "    num_terrain = []\n",
    "    num_sky = []\n",
    "    num_person = []\n",
    "    num_rider = []\n",
    "    num_car = []\n",
    "    num_truck = []\n",
    "    num_bus = []\n",
    "    num_train = []\n",
    "    num_motorcycle = []\n",
    "    num_bicycle = []\n",
    "    num_lanes = []\n",
    "    num_drivable_area = []\n",
    "\n",
    "    # Iterate through each image in train_labels_normalized, sum up the number of objects corresponding to each object type, and append to\n",
    "    # the corresponding object list\n",
    "    for index, row in labels_normalized.iterrows():\n",
    "        num_objects.append(len(row['labels']))\n",
    "        num_road.append(sum(x['category'] == 'road' for x in row['labels']))\n",
    "        num_sidewalk.append(sum(x['category'] == 'sidewalk' for x in row['labels']))\n",
    "        num_building.append(sum(x['category'] == 'building' for x in row['labels']))\n",
    "        num_wall.append(sum(x['category'] == 'wall' for x in row['labels']))\n",
    "        num_fence.append(sum(x['category'] == 'fence' for x in row['labels']))\n",
    "        num_pole.append(sum(x['category'] == 'pole' for x in row['labels']))\n",
    "        num_traffic_light.append(sum(x['category'] == 'traffic light' for x in row['labels']))\n",
    "        num_traffic_sign.append(sum(x['category'] == 'traffic sign' for x in row['labels']))\n",
    "        num_vegetation.append(sum(x['category'] == 'vegetation' for x in row['labels']))\n",
    "        num_terrain.append(sum(x['category'] == 'terrain' for x in row['labels']))\n",
    "        num_sky.append(sum(x['category'] == 'sky' for x in row['labels']))\n",
    "        num_person.append(sum(x['category'] == 'person' for x in row['labels']))\n",
    "        num_rider.append(sum(x['category'] == 'rider' for x in row['labels']))\n",
    "        num_car.append(sum(x['category'] == 'car' for x in row['labels']))\n",
    "        num_truck.append(sum(x['category'] == 'truck' for x in row['labels']))\n",
    "        num_bus.append(sum(x['category'] == 'bus' for x in row['labels']))\n",
    "        num_train.append(sum(x['category'] == 'train' for x in row['labels']))\n",
    "        num_motorcycle.append(sum(x['category'] == 'motorcycle' for x in row['labels']))\n",
    "        num_bicycle.append(sum(x['category'] == 'bicycle' for x in row['labels']))\n",
    "        num_lanes.append(sum(x['category'] == 'lane' for x in row['labels']))\n",
    "        num_drivable_area.append(sum(x['category'] == 'drivable area' for x in row['labels']))\n",
    "\n",
    "    labels_normalized['num_objects'] = num_objects\n",
    "    labels_normalized['num_sidewalk'] = num_sidewalk\n",
    "    labels_normalized['num_building'] = num_building\n",
    "    labels_normalized['num_wall'] = num_wall\n",
    "    labels_normalized['num_fence'] = num_fence\n",
    "    labels_normalized['num_pole'] = num_pole\n",
    "    labels_normalized['num_traffic_light'] = num_traffic_light\n",
    "    labels_normalized['num_traffic_sign'] = num_traffic_sign\n",
    "    labels_normalized['num_vegetation'] = num_vegetation\n",
    "    labels_normalized['num_terrain'] = num_terrain\n",
    "    labels_normalized['num_sky'] = num_sky\n",
    "    labels_normalized['num_person'] = num_person\n",
    "    labels_normalized['num_rider'] = num_rider\n",
    "    labels_normalized['num_car'] = num_car\n",
    "    labels_normalized['num_truck'] = num_truck\n",
    "    labels_normalized['num_bus'] = num_bus\n",
    "    labels_normalized['num_train'] = num_train\n",
    "    labels_normalized['num_motorcycle'] = num_motorcycle\n",
    "    labels_normalized['num_bicycle'] = num_bicycle\n",
    "    labels_normalized['num_lanes'] = num_lanes\n",
    "    labels_normalized['num_drivable_area'] = num_drivable_area\n",
    "\n",
    "    # Filter only for images where weather == \"clear\", scene == \"highway\", and timeofday == \"daytime\". \n",
    "    # Note: A better implementation may be to filter the dataframe prior to counting the objects per image, \n",
    "    # but it may be useful to keep the train_labels_normalized and object counts for each image in case we want to use different filtering values.\n",
    "\n",
    "    labels_cleaned = labels_normalized[(labels_normalized['attributes.weather'] == \"clear\") & \n",
    "                   (labels_normalized['attributes.scene'] == \"highway\") & \n",
    "                   (labels_normalized['attributes.timeofday'] == \"daytime\")]\n",
    "    return labels_cleaned\n",
    "\n",
    "# Clean Training & Validation Labels\n",
    "train_labels_cleaned = clean_data(train_labels_normalized)\n",
    "\n",
    "# Clean Test Labels\n",
    "test_labels_cleaned = clean_data(test_labels_normalized)\n",
    "\n",
    "# Split training dataset to training and validation\n",
    "train_labels_split = train_labels_cleaned.sample(frac = 0.9)\n",
    "val_labels_split = train_labels_cleaned.drop(train_labels_split.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e287329e-7bcc-446b-9bd9-2724b4b97067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure if this is needed yet\n",
    "def flatten_json(y):\n",
    "        out = {}\n",
    "\n",
    "        def flatten(x, name=''):\n",
    "            if type(x) is dict:\n",
    "                for a in x:\n",
    "                    flatten(x[a], name + a + '_')\n",
    "            elif type(x) is list:\n",
    "                i = 0\n",
    "                for a in x:\n",
    "                    flatten(a, name + str(i) + '_')\n",
    "                    i += 1\n",
    "            else:\n",
    "                out[name[:-1]] = x\n",
    "\n",
    "        flatten(y)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346220b0-c6d6-4b82-b034-58a1ea7aa3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConfig(Config):\n",
    "    \"\"\"Configuration for training on the custom  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"object\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + drivable area\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 10\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de0df49b-27a5-4660-9500-4809b6e29bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(utils.Dataset):\n",
    "\n",
    "    def load_custom(self, dataset_dir, subset):\n",
    "\n",
    "        \"\"\"Load a subset of the driving dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "\n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"object\", 1, \"drivable area\")\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset + \"_clean\")\n",
    "\n",
    "        # Given an image (i.e. a row in train_labels_split)\n",
    "        # Get all the items that are considered drivable area\n",
    "        # For each item, save the x and y vertices into two lists\n",
    "\n",
    "        for index, image in train_labels_split.iterrows():\n",
    "\n",
    "            polygons = []\n",
    "            objects = []\n",
    "            for obj in image['labels']:\n",
    "                x = []\n",
    "                y = []\n",
    "                if obj['category'] == 'drivable area':\n",
    "                    for coord in obj['poly2d'][0]['vertices']:\n",
    "                        x.append(coord[0])\n",
    "                        y.append(coord[1])\n",
    "                    polygons.append({'name': 'polygon', \n",
    "                                      'all_points_x': x, \n",
    "                                      'all_points_y': y})\n",
    "                    objects.append('drivable area')\n",
    "\n",
    "            image_path = os.path.join(dataset_dir, image['name'])\n",
    "            \n",
    "            # Only use commented code if have more than 1 object. Otherwise use the uncommented one that sets 1 to all objects\n",
    "            # name_dict = {\"Car\": 1,\"Truck\": 2}\n",
    "            # num_ids = [name_dict[a] for a in objects]\n",
    "            num_ids = [1 for a in objects]\n",
    "            \n",
    "            # Don't need to do these steps because all images are the same height and width\n",
    "            # img = skimage.io.imread(image_path)\n",
    "            # height, width = img.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"object\",  ## for a single class just add the name here\n",
    "                image_id=image['name'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=1280, height=720,\n",
    "                polygons=polygons,\n",
    "                num_ids=num_ids\n",
    "                )\n",
    "        return\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a Dog-Cat dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "        num_ids = info['num_ids']\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "        \trr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "\n",
    "        \tmask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        # Map class names to class IDs.\n",
    "        num_ids = np.array(num_ids, dtype=np.int32)\n",
    "        return mask, num_ids #np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "    \n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"object\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42491a3f-054b-416e-a15c-5cb87ed62a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = CustomDataset()\n",
    "    dataset_train.load_custom(ROOT_DIR, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = CustomDataset()\n",
    "    dataset_val.load_custom(\"ROOT_DIR\", \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "    # Since we're using a very small dataset, and starting from\n",
    "    # COCO trained weights, we don't need to train too long. Also,\n",
    "    # no need to train all layers, just the heads should do it.\n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=20,\n",
    "                layers='heads')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e37503a-21d8-4703-bf86-8a95d72cdef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bbfc10-b9c0-4a34-adb9-60762471f388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /Users/tiffanyshih/Documents/Coursework/MIDS_207/Final_Project/logs/object20220401T1447/mask_rcnn_object_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "config = CustomConfig()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=DEFAULT_LOGS_DIR)\n",
    "\n",
    "weights_path = COCO_WEIGHTS_PATH\n",
    "        # Download weights file\n",
    "if not os.path.exists(weights_path):\n",
    "  utils.download_trained_weights(weights_path)\n",
    "\n",
    "model.load_weights(weights_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab64ed-daf5-45f0-b600-e1ef349c154d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
