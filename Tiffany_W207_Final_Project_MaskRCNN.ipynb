{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799cdfb3-8328-4083-8e03-126af51ec7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import skimage.draw\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from multiprocessing import freeze_support\n",
    "from google.cloud import storage\n",
    "from IPython.display import Image\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61281e86-a797-433b-a24a-60ec6e6c2932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514\n"
     ]
    }
   ],
   "source": [
    "# DON'T NEED TO RUN THIS AGAIN\n",
    "# client = storage.Client()\n",
    "# DATA_BUCKET = 'w207-final-project'\n",
    "# databucket = client.get_bucket(DATA_BUCKET)\n",
    "# datafiles = databucket.list_blobs()\n",
    "# files=[a.name for a in datafiles if a.name.startswith('train_clean')]\n",
    "# # files=[a.name for a in datafiles if a.name.startswith('val_clean')]\n",
    "# files=[a.name for a in datafiles if a.name.startswith('test_clean')]\n",
    "# # files=[a.name for a in datafiles if a.name.endswith('.json')]\n",
    "# # print(files)\n",
    "# Copy files from bucket into local folder\n",
    "# for file in files:\n",
    "#     blob = databucket.get_blob(file)\n",
    "#     blob.download_to_filename(file)\n",
    "\n",
    "\n",
    "\n",
    "# Check if all files are copied over\n",
    "list = os.listdir('test_clean') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print(number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d9853d-ff4f-460e-a716-69bd3e361443",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(\"\")\n",
    "\n",
    "# Path to trained weights file\n",
    "# Original weights path\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# New weights path\n",
    "# COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"logs/object20220406T0321/mask_rcnn_object_0020.h5\")\n",
    "\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ed1939-9a44-49d6-8732-0ac39a2bed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomConfig(Config):\n",
    "    \"\"\"Configuration for training on the custom  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"object\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    # ADJUSTED FROM IMAGES_PER_GPU = 2, MAY CHANGE BACK IF USING CLOUD\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + drivable area\n",
    "    # NUM_CLASSES = 1 + 2  # Background + drivable area + lane\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    # REMEMBER TO CHANGE AFTER TESTING\n",
    "    STEPS_PER_EPOCH = 2\n",
    "    # STEPS_PER_EPOCH = 10\n",
    "\n",
    "    # Number of validation steps to run at the end of every training epoch.\n",
    "    # A bigger number improves accuracy of validation stats, but slows\n",
    "    # down the training.\n",
    "    # START SMALLER?\n",
    "    # VALIDATION_STEPS = 10\n",
    "    VALIDATION_STEPS = 10\n",
    "    \n",
    "    # Supported values are: resnet50, resnet101.\n",
    "    # You can also provide a callable that should have the signature\n",
    "    # of model.resnet_graph. If you do so, you need to supply a callable\n",
    "    # to COMPUTE_BACKBONE_SHAPE as well\n",
    "    # BACKBONE = \"resnet101\" # Default\n",
    "    BACKGONE = \"resnet50\"\n",
    "\n",
    "    # Skip detections below % confidence specified\n",
    "    # DETECTION_MIN_CONFIDENCE = 0.5\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ea7f8f5-ab73-4375-b03a-a6c4b965ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomDataset(utils.Dataset):\n",
    "\n",
    "    def load_custom(self, dataset_dir, subset):\n",
    "\n",
    "        \"\"\"Load a subset of the driving dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "\n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"object\", 1, \"drivable area\")\n",
    "        # self.add_class(\"object\", 2, \"lane\")\n",
    "        \n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset + \"_clean\")\n",
    "        # dataset_dir = os.path.join(dataset_dir, subset + \"_test\")\n",
    "\n",
    "        # Given an image (i.e. a row in train_labels_split)\n",
    "        # Get all the items that are considered drivable area\n",
    "        # For each item, save the x and y vertices into two lists\n",
    "        \n",
    "        if subset == 'train':\n",
    "            labels = train_labels_cleaned\n",
    "        else:\n",
    "            labels = val_labels_cleaned\n",
    "            \n",
    "        for index, image in labels.iterrows():\n",
    "\n",
    "            polygons = []\n",
    "            objects = []\n",
    "            for obj in image['labels']:\n",
    "                x = []\n",
    "                y = []\n",
    "                if obj['category'] == 'drivable area':\n",
    "                    for coord in obj['poly2d'][0]['vertices']:\n",
    "                        if coord[0] >= 1280:\n",
    "                            x.append(1279)\n",
    "                        else:\n",
    "                            x.append(coord[0])\n",
    "                        if coord[1] >= 720:\n",
    "                            y.append(719)\n",
    "                        else:\n",
    "                            y.append(coord[1])\n",
    "                    polygons.append({'name': 'polygon',\n",
    "                                      'all_points_x': x,\n",
    "                                      'all_points_y': y})\n",
    "                    objects.append('drivable area')\n",
    "                # elif obj['category'] == 'lane':\n",
    "                #     for coord in obj['poly2d'][0]['vertices']:\n",
    "                #         if coord[0] >= 1280:\n",
    "                #             x.append(1279)\n",
    "                #         else:\n",
    "                #             x.append(coord[0])\n",
    "                #         if coord[1] >= 720:\n",
    "                #             y.append(719)\n",
    "                #         else:\n",
    "                #             y.append(coord[1])\n",
    "                #     polygons.append({'name': 'polygon',\n",
    "                #                       'all_points_x': x,\n",
    "                #                       'all_points_y': y})\n",
    "                #     objects.append('lane')\n",
    "                    \n",
    "            image_path = os.path.join(dataset_dir, image['name'])\n",
    "\n",
    "            # Only use commented code if trying out drivable area and lane. Use the uncommented code for just drivable area evaluation\n",
    "            name_dict = {\"drivable area\": 1}\n",
    "            # name_dict = {\"drivable area\": 1,\"lane\": 2}\n",
    "            \n",
    "            num_ids = [name_dict[a] for a in objects]\n",
    "\n",
    "            self.add_image(\n",
    "                \"object\",  ## for a single class just add the name here\n",
    "                image_id=image['name'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=1280, height=720,\n",
    "                polygons=polygons,\n",
    "                num_ids=num_ids\n",
    "                )\n",
    "        return\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a Dog-Cat dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "        num_ids = info['num_ids']\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "        \trr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "\n",
    "        \tmask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        # Map class names to class IDs.\n",
    "        num_ids = np.array(num_ids, dtype=np.int32)\n",
    "        return mask, num_ids #np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"object\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afdb972a-5fdc-42e5-9524-0a3f981d5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = CustomDataset()\n",
    "    dataset_train.load_custom(ROOT_DIR, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = CustomDataset()\n",
    "    dataset_val.load_custom(ROOT_DIR, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "    # Since we're using a very small dataset, and starting from\n",
    "    # COCO trained weights, we don't need to train too long. Also,\n",
    "    # no need to train all layers, just the heads should do it.\n",
    "    print(\"Training network heads\")\n",
    "\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=40,\n",
    "                layers='heads')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5461756e-b738-4581-93af-da9a93bc3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON files for image segment labels\n",
    "\n",
    "with open('test/train_clean/bdd100k_labels_images_train.json') as json_file:\n",
    "    train_labels = json.load(json_file)\n",
    "\n",
    "with open('val_clean/bdd100k_labels_images_val.json') as json_file:\n",
    "    val_labels = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1340050e-554a-4897-b725-2f5b10b14b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# REQUIRED: Normalize semi-structured JSON data into a pd dataframe\n",
    "# Note that train_labels json file contains both labels for training and validation set \n",
    "train_labels_normalized = pd.json_normalize(train_labels)\n",
    "\n",
    "train_filenames = []\n",
    "val_filenames = []\n",
    "\n",
    "# REMEMBER TO REPLACE AFTER INITIAL TESTING\n",
    "for myfile in os.listdir(ROOT_DIR + \"/train_clean\"):\n",
    "    if myfile.endswith(\".jpg\"):\n",
    "        train_filenames.append(os.path.join(myfile))\n",
    "\n",
    "for myfile in os.listdir(ROOT_DIR + \"/val_clean\"):\n",
    "    if myfile.endswith(\".jpg\"):\n",
    "        val_filenames.append(os.path.join(myfile))\n",
    "\n",
    "# Save labels for only the images within the folder contents\n",
    "train_labels_cleaned = train_labels_normalized.loc[train_labels_normalized['name'].isin(train_filenames)]\n",
    "\n",
    "# val_labels_split\n",
    "val_labels_cleaned = train_labels_normalized.loc[train_labels_normalized['name'].isin(val_filenames)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39082542-e41d-4e38-b854-64ee31cea6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c15549a-320a-40d4-84b7-9220d356d79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 17:54:34.351727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 17:54:34.352501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 17:54:34.353313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 17:54:34.354028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 17:54:34.354711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 17:54:34.355295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13821 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = CustomConfig()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=DEFAULT_LOGS_DIR)\n",
    "\n",
    "weights_path = COCO_WEIGHTS_PATH\n",
    "        # Download weights file\n",
    "if not os.path.exists(weights_path):\n",
    "  utils.download_trained_weights(weights_path)\n",
    "\n",
    "model.load_weights(weights_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f07158e8-dfaa-48a8-b629-f89c1abcf62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/jupyter/logs/object20220409T1754/mask_rcnn_object_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "2022-04-09 17:54:46.678064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 17:54:46.678482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 17:54:46.678759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 17:54:46.679086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 17:54:46.679378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 17:54:46.679629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13821 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "2022-04-09 17:55:23.227598: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -540 } dim { size: 56 } dim { size: 56 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -25 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -25 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -25 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "2022-04-09 17:55:23.231038: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -130 } dim { size: -131 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -36 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:23.231177: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -130 } dim { size: -131 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -36 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:23.231308: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -138 } dim { size: -139 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -39 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -39 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -39 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:23.231532: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -138 } dim { size: -139 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -39 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -39 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -39 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:23.231715: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -146 } dim { size: -147 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -41 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:23.231896: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -146 } dim { size: -147 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -41 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:23.232132: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -122 } dim { size: -123 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -43 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -43 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -43 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:23.232434: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -14 } dim { size: -122 } dim { size: -123 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -43 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -43 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -43 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:25.054343: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 18s - batch: 0.0000e+00 - size: 1.0000 - loss: 37.1341 - rpn_class_loss: 15.8546 - rpn_bbox_loss: 12.3023 - mrcnn_class_loss: 8.9772 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 17:55:35.950865: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-04-09 17:55:35.950903: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-04-09 17:55:35.952423: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\n",
      "2022-04-09 17:55:35.952928: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-04-09 17:55:36.964370: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-04-09 17:55:36.965285: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n",
      "2022-04-09 17:55:37.033620: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 2424 callback api events and 2423 activity events. \n",
      "2022-04-09 17:55:37.096681: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-04-09 17:55:37.175272: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /home/jupyter/logs/object20220409T1754/plugins/profile/2022_04_09_17_55_37\n",
      "\n",
      "2022-04-09 17:55:37.224394: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to /home/jupyter/logs/object20220409T1754/plugins/profile/2022_04_09_17_55_37/w207-final-project.trace.json.gz\n",
      "2022-04-09 17:55:37.340388: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /home/jupyter/logs/object20220409T1754/plugins/profile/2022_04_09_17_55_37\n",
      "\n",
      "2022-04-09 17:55:37.349280: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to /home/jupyter/logs/object20220409T1754/plugins/profile/2022_04_09_17_55_37/w207-final-project.memory_profile.json.gz\n",
      "2022-04-09 17:55:37.353677: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /home/jupyter/logs/object20220409T1754/plugins/profile/2022_04_09_17_55_37\n",
      "Dumped tool data for xplane.pb to /home/jupyter/logs/object20220409T1754/plugins/profile/2022_04_09_17_55_37/w207-final-project.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /home/jupyter/logs/object20220409T1754/plugins/profile/2022_04_09_17_55_37/w207-final-project.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /home/jupyter/logs/object20220409T1754/plugins/profile/2022_04_09_17_55_37/w207-final-project.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /home/jupyter/logs/object20220409T1754/plugins/profile/2022_04_09_17_55_37/w207-final-project.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /home/jupyter/logs/object20220409T1754/plugins/profile/2022_04_09_17_55_37/w207-final-project.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - batch: 0.5000 - size: 1.0000 - loss: 27.0627 - rpn_class_loss: 11.6807 - rpn_bbox_loss: 10.8933 - mrcnn_class_loss: 4.4886 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2022-04-09 17:55:41.340053: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -395 } dim { size: 56 } dim { size: 56 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -12 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -12 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -12 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "2022-04-09 17:55:41.346002: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -324 } dim { size: -325 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -23 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -23 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -23 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:41.347000: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -324 } dim { size: -325 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -23 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -23 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -23 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:41.347835: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -314 } dim { size: -315 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -26 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:41.348438: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -314 } dim { size: -315 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -26 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:41.349145: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -302 } dim { size: -303 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -28 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -28 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -28 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:41.349706: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -302 } dim { size: -303 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -28 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -28 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -28 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:41.350389: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -288 } dim { size: -289 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -30 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-04-09 17:55:41.350934: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: -288 } dim { size: -289 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -30 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14493155328 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 50s 31s/step - batch: 0.5000 - size: 1.0000 - loss: 27.0627 - rpn_class_loss: 11.6807 - rpn_bbox_loss: 10.8933 - mrcnn_class_loss: 4.4886 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 6.8463 - val_rpn_class_loss: 0.9560 - val_rpn_bbox_loss: 5.8902 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 6s 6s/step - batch: 0.5000 - size: 1.0000 - loss: 9.8695 - rpn_class_loss: 0.6442 - rpn_bbox_loss: 4.8844 - mrcnn_class_loss: 0.0250 - mrcnn_bbox_loss: 3.8452 - mrcnn_mask_loss: 0.4706 - val_loss: 9.2958 - val_rpn_class_loss: 0.2353 - val_rpn_bbox_loss: 4.5947 - val_mrcnn_class_loss: 0.0502 - val_mrcnn_bbox_loss: 3.5944 - val_mrcnn_mask_loss: 0.8213\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 9s 8s/step - batch: 0.5000 - size: 1.0000 - loss: 7.9673 - rpn_class_loss: 0.2550 - rpn_bbox_loss: 5.9525 - mrcnn_class_loss: 0.0144 - mrcnn_bbox_loss: 1.4187 - mrcnn_mask_loss: 0.3268 - val_loss: 10.4584 - val_rpn_class_loss: 0.1081 - val_rpn_bbox_loss: 4.8515 - val_mrcnn_class_loss: 0.1381 - val_mrcnn_bbox_loss: 4.1920 - val_mrcnn_mask_loss: 1.1687\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 8s 8s/step - batch: 0.5000 - size: 1.0000 - loss: 16.0920 - rpn_class_loss: 0.0457 - rpn_bbox_loss: 8.0734 - mrcnn_class_loss: 0.4033 - mrcnn_bbox_loss: 6.4013 - mrcnn_mask_loss: 1.1683 - val_loss: 12.4213 - val_rpn_class_loss: 0.0486 - val_rpn_bbox_loss: 7.4698 - val_mrcnn_class_loss: 0.1179 - val_mrcnn_bbox_loss: 4.0768 - val_mrcnn_mask_loss: 0.7084\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 10.4414 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 6.4274 - mrcnn_class_loss: 0.2383 - mrcnn_bbox_loss: 3.0451 - mrcnn_mask_loss: 0.7283 - val_loss: 9.4899 - val_rpn_class_loss: 0.0107 - val_rpn_bbox_loss: 7.2188 - val_mrcnn_class_loss: 0.0714 - val_mrcnn_bbox_loss: 1.4837 - val_mrcnn_mask_loss: 0.7053\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 9.7167 - rpn_class_loss: 1.0408e-04 - rpn_bbox_loss: 5.6264 - mrcnn_class_loss: 0.1918 - mrcnn_bbox_loss: 3.1935 - mrcnn_mask_loss: 0.7049 - val_loss: 5.4130 - val_rpn_class_loss: 6.0993e-04 - val_rpn_bbox_loss: 2.4517 - val_mrcnn_class_loss: 0.0456 - val_mrcnn_bbox_loss: 2.2139 - val_mrcnn_mask_loss: 0.7012\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 6.1145 - rpn_class_loss: 8.4552e-06 - rpn_bbox_loss: 2.7974 - mrcnn_class_loss: 0.1075 - mrcnn_bbox_loss: 2.5366 - mrcnn_mask_loss: 0.6730 - val_loss: 7.1366 - val_rpn_class_loss: 5.2396e-04 - val_rpn_bbox_loss: 4.6493 - val_mrcnn_class_loss: 0.0697 - val_mrcnn_bbox_loss: 1.7509 - val_mrcnn_mask_loss: 0.6661\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 10s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 6.0529 - rpn_class_loss: 1.6101e-06 - rpn_bbox_loss: 3.0771 - mrcnn_class_loss: 0.2078 - mrcnn_bbox_loss: 2.1262 - mrcnn_mask_loss: 0.6417 - val_loss: 6.9420 - val_rpn_class_loss: 9.5115e-04 - val_rpn_bbox_loss: 3.8300 - val_mrcnn_class_loss: 0.2116 - val_mrcnn_bbox_loss: 2.2212 - val_mrcnn_mask_loss: 0.6782\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 6.8460 - rpn_class_loss: 3.8502e-05 - rpn_bbox_loss: 4.8443 - mrcnn_class_loss: 0.0428 - mrcnn_bbox_loss: 1.3005 - mrcnn_mask_loss: 0.6584 - val_loss: 10.3996 - val_rpn_class_loss: 9.9904e-04 - val_rpn_bbox_loss: 7.5035 - val_mrcnn_class_loss: 0.0429 - val_mrcnn_bbox_loss: 2.2521 - val_mrcnn_mask_loss: 0.6002\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 11.5104 - rpn_class_loss: 2.2799e-05 - rpn_bbox_loss: 8.4730 - mrcnn_class_loss: 0.0181 - mrcnn_bbox_loss: 2.4008 - mrcnn_mask_loss: 0.6185 - val_loss: 9.8879 - val_rpn_class_loss: 7.2582e-04 - val_rpn_bbox_loss: 6.8254 - val_mrcnn_class_loss: 0.0918 - val_mrcnn_bbox_loss: 2.3345 - val_mrcnn_mask_loss: 0.6356\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 8.6904 - rpn_class_loss: 8.1241e-06 - rpn_bbox_loss: 5.6804 - mrcnn_class_loss: 0.0563 - mrcnn_bbox_loss: 2.3731 - mrcnn_mask_loss: 0.5806 - val_loss: 5.0121 - val_rpn_class_loss: 8.0160e-04 - val_rpn_bbox_loss: 3.3467 - val_mrcnn_class_loss: 0.1902 - val_mrcnn_bbox_loss: 0.8545 - val_mrcnn_mask_loss: 0.6199\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 3.6928 - rpn_class_loss: 6.1587e-06 - rpn_bbox_loss: 2.9626 - mrcnn_class_loss: 0.0703 - mrcnn_bbox_loss: 0.3622 - mrcnn_mask_loss: 0.2977 - val_loss: 4.5974 - val_rpn_class_loss: 8.7110e-04 - val_rpn_bbox_loss: 3.4796 - val_mrcnn_class_loss: 0.0250 - val_mrcnn_bbox_loss: 0.9582 - val_mrcnn_mask_loss: 0.1338\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 7.5524 - rpn_class_loss: 6.3882e-05 - rpn_bbox_loss: 2.5957 - mrcnn_class_loss: 0.0391 - mrcnn_bbox_loss: 4.2402 - mrcnn_mask_loss: 0.6774 - val_loss: 7.9092 - val_rpn_class_loss: 6.3911e-04 - val_rpn_bbox_loss: 3.7173 - val_mrcnn_class_loss: 0.0132 - val_mrcnn_bbox_loss: 3.5996 - val_mrcnn_mask_loss: 0.5784\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 11s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 2.8296 - rpn_class_loss: 6.8370e-05 - rpn_bbox_loss: 2.8296 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 3.2097 - val_rpn_class_loss: 5.8341e-04 - val_rpn_bbox_loss: 2.1680 - val_mrcnn_class_loss: 0.0053 - val_mrcnn_bbox_loss: 0.9063 - val_mrcnn_mask_loss: 0.1296\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 5.1538 - rpn_class_loss: 7.1143e-05 - rpn_bbox_loss: 1.1437 - mrcnn_class_loss: 0.1098 - mrcnn_bbox_loss: 3.3012 - mrcnn_mask_loss: 0.5991 - val_loss: 7.7142 - val_rpn_class_loss: 8.7982e-04 - val_rpn_bbox_loss: 5.7908 - val_mrcnn_class_loss: 0.0467 - val_mrcnn_bbox_loss: 1.2673 - val_mrcnn_mask_loss: 0.6085\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 5.6484 - rpn_class_loss: 1.6229e-04 - rpn_bbox_loss: 3.5036 - mrcnn_class_loss: 0.0401 - mrcnn_bbox_loss: 1.5448 - mrcnn_mask_loss: 0.5597 - val_loss: 8.8026 - val_rpn_class_loss: 0.0015 - val_rpn_bbox_loss: 6.7299 - val_mrcnn_class_loss: 0.0167 - val_mrcnn_bbox_loss: 1.4805 - val_mrcnn_mask_loss: 0.5740\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 18.6770 - rpn_class_loss: 3.3321 - rpn_bbox_loss: 15.3449 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 7.1909 - val_rpn_class_loss: 0.0071 - val_rpn_bbox_loss: 3.3449 - val_mrcnn_class_loss: 0.0840 - val_mrcnn_bbox_loss: 3.1733 - val_mrcnn_mask_loss: 0.5816\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 13.6777 - rpn_class_loss: 2.7205 - rpn_bbox_loss: 7.3133 - mrcnn_class_loss: 0.0380 - mrcnn_bbox_loss: 3.3176 - mrcnn_mask_loss: 0.2882 - val_loss: 4.8903 - val_rpn_class_loss: 0.0147 - val_rpn_bbox_loss: 2.7143 - val_mrcnn_class_loss: 0.0013 - val_mrcnn_bbox_loss: 1.5770 - val_mrcnn_mask_loss: 0.5829\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 16.5372 - rpn_class_loss: 1.7613 - rpn_bbox_loss: 5.8627 - mrcnn_class_loss: 0.3697 - mrcnn_bbox_loss: 7.6736 - mrcnn_mask_loss: 0.8699 - val_loss: 4.2166 - val_rpn_class_loss: 0.0154 - val_rpn_bbox_loss: 4.2012 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 11s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 10.4620 - rpn_class_loss: 0.6941 - rpn_bbox_loss: 7.3641 - mrcnn_class_loss: 2.9750e-04 - mrcnn_bbox_loss: 1.8485 - mrcnn_mask_loss: 0.5550 - val_loss: 6.5895 - val_rpn_class_loss: 0.4130 - val_rpn_bbox_loss: 4.1166 - val_mrcnn_class_loss: 0.0116 - val_mrcnn_bbox_loss: 1.9284 - val_mrcnn_mask_loss: 0.1199\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 6.6853 - rpn_class_loss: 0.7689 - rpn_bbox_loss: 4.5413 - mrcnn_class_loss: 0.0239 - mrcnn_bbox_loss: 0.9744 - mrcnn_mask_loss: 0.3769 - val_loss: 6.1269 - val_rpn_class_loss: 0.7385 - val_rpn_bbox_loss: 2.8100 - val_mrcnn_class_loss: 0.1470 - val_mrcnn_bbox_loss: 1.8401 - val_mrcnn_mask_loss: 0.5913\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 9s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 5.3650 - rpn_class_loss: 0.4644 - rpn_bbox_loss: 2.0379 - mrcnn_class_loss: 0.1615 - mrcnn_bbox_loss: 2.0109 - mrcnn_mask_loss: 0.6903 - val_loss: 7.5800 - val_rpn_class_loss: 0.0724 - val_rpn_bbox_loss: 2.3479 - val_mrcnn_class_loss: 0.0540 - val_mrcnn_bbox_loss: 4.3970 - val_mrcnn_mask_loss: 0.7086\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 10s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 4.0011 - rpn_class_loss: 0.0151 - rpn_bbox_loss: 2.9161 - mrcnn_class_loss: 2.4133e-04 - mrcnn_bbox_loss: 0.7242 - mrcnn_mask_loss: 0.3454 - val_loss: 5.3373 - val_rpn_class_loss: 0.0299 - val_rpn_bbox_loss: 2.7749 - val_mrcnn_class_loss: 0.0288 - val_mrcnn_bbox_loss: 1.8751 - val_mrcnn_mask_loss: 0.6287\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 10s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 6.0108 - rpn_class_loss: 2.1545e-04 - rpn_bbox_loss: 3.0178 - mrcnn_class_loss: 0.0164 - mrcnn_bbox_loss: 2.3371 - mrcnn_mask_loss: 0.6392 - val_loss: 7.0671 - val_rpn_class_loss: 0.0200 - val_rpn_bbox_loss: 4.3642 - val_mrcnn_class_loss: 0.0487 - val_mrcnn_bbox_loss: 1.9949 - val_mrcnn_mask_loss: 0.6392\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 10s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 7.7891 - rpn_class_loss: 0.3390 - rpn_bbox_loss: 3.3314 - mrcnn_class_loss: 0.0220 - mrcnn_bbox_loss: 3.4953 - mrcnn_mask_loss: 0.6014 - val_loss: 6.2902 - val_rpn_class_loss: 0.0134 - val_rpn_bbox_loss: 3.9091 - val_mrcnn_class_loss: 0.0490 - val_mrcnn_bbox_loss: 1.6771 - val_mrcnn_mask_loss: 0.6414\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 11s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 4.5969 - rpn_class_loss: 0.2932 - rpn_bbox_loss: 2.5762 - mrcnn_class_loss: 0.0046 - mrcnn_bbox_loss: 1.3932 - mrcnn_mask_loss: 0.3297 - val_loss: 6.0234 - val_rpn_class_loss: 0.0090 - val_rpn_bbox_loss: 2.0682 - val_mrcnn_class_loss: 0.0999 - val_mrcnn_bbox_loss: 3.1771 - val_mrcnn_mask_loss: 0.6691\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 7.3509 - rpn_class_loss: 0.1658 - rpn_bbox_loss: 2.2015 - mrcnn_class_loss: 0.0155 - mrcnn_bbox_loss: 4.6748 - mrcnn_mask_loss: 0.2933 - val_loss: 8.2643 - val_rpn_class_loss: 0.0232 - val_rpn_bbox_loss: 2.3827 - val_mrcnn_class_loss: 0.1154 - val_mrcnn_bbox_loss: 5.0386 - val_mrcnn_mask_loss: 0.7044\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 9.6468 - rpn_class_loss: 0.0861 - rpn_bbox_loss: 3.8910 - mrcnn_class_loss: 0.0018 - mrcnn_bbox_loss: 5.0119 - mrcnn_mask_loss: 0.6560 - val_loss: 7.7356 - val_rpn_class_loss: 0.0537 - val_rpn_bbox_loss: 4.2463 - val_mrcnn_class_loss: 0.0150 - val_mrcnn_bbox_loss: 2.7640 - val_mrcnn_mask_loss: 0.6566\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 4.9667 - rpn_class_loss: 0.0158 - rpn_bbox_loss: 2.4910 - mrcnn_class_loss: 0.0045 - mrcnn_bbox_loss: 1.7942 - mrcnn_mask_loss: 0.6613 - val_loss: 8.4216 - val_rpn_class_loss: 0.0759 - val_rpn_bbox_loss: 5.2206 - val_mrcnn_class_loss: 0.0319 - val_mrcnn_bbox_loss: 2.4314 - val_mrcnn_mask_loss: 0.6618\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 10s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 3.3118 - rpn_class_loss: 0.0222 - rpn_bbox_loss: 1.1851 - mrcnn_class_loss: 0.0196 - mrcnn_bbox_loss: 1.4464 - mrcnn_mask_loss: 0.6386 - val_loss: 7.2208 - val_rpn_class_loss: 0.0612 - val_rpn_bbox_loss: 4.0366 - val_mrcnn_class_loss: 0.0340 - val_mrcnn_bbox_loss: 2.4259 - val_mrcnn_mask_loss: 0.6632\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 5.2759 - rpn_class_loss: 0.0107 - rpn_bbox_loss: 0.9594 - mrcnn_class_loss: 0.0256 - mrcnn_bbox_loss: 3.6170 - mrcnn_mask_loss: 0.6631 - val_loss: 6.6831 - val_rpn_class_loss: 0.0504 - val_rpn_bbox_loss: 4.6130 - val_mrcnn_class_loss: 0.0247 - val_mrcnn_bbox_loss: 1.3571 - val_mrcnn_mask_loss: 0.6378\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 10s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 3.8267 - rpn_class_loss: 0.0080 - rpn_bbox_loss: 0.6980 - mrcnn_class_loss: 0.0616 - mrcnn_bbox_loss: 2.4558 - mrcnn_mask_loss: 0.6033 - val_loss: 8.0030 - val_rpn_class_loss: 0.0494 - val_rpn_bbox_loss: 5.7673 - val_mrcnn_class_loss: 0.0322 - val_mrcnn_bbox_loss: 1.5162 - val_mrcnn_mask_loss: 0.6379\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 6.4868 - rpn_class_loss: 0.1011 - rpn_bbox_loss: 4.5854 - mrcnn_class_loss: 0.0053 - mrcnn_bbox_loss: 1.1652 - mrcnn_mask_loss: 0.6298 - val_loss: 6.8484 - val_rpn_class_loss: 0.0253 - val_rpn_bbox_loss: 4.5452 - val_mrcnn_class_loss: 0.0428 - val_mrcnn_bbox_loss: 1.6130 - val_mrcnn_mask_loss: 0.6220\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 5.7229 - rpn_class_loss: 0.0092 - rpn_bbox_loss: 2.9345 - mrcnn_class_loss: 0.1182 - mrcnn_bbox_loss: 2.0174 - mrcnn_mask_loss: 0.6437 - val_loss: 5.6451 - val_rpn_class_loss: 0.0125 - val_rpn_bbox_loss: 2.8447 - val_mrcnn_class_loss: 0.0551 - val_mrcnn_bbox_loss: 2.0437 - val_mrcnn_mask_loss: 0.6890\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 11s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 5.9172 - rpn_class_loss: 3.1636e-04 - rpn_bbox_loss: 1.9883 - mrcnn_class_loss: 0.1661 - mrcnn_bbox_loss: 3.0428 - mrcnn_mask_loss: 0.7196 - val_loss: 4.2999 - val_rpn_class_loss: 0.0131 - val_rpn_bbox_loss: 4.2868 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 3.8764 - rpn_class_loss: 3.0086e-05 - rpn_bbox_loss: 3.8764 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 4.6519 - val_rpn_class_loss: 0.0147 - val_rpn_bbox_loss: 4.6371 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 11s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 5.3098 - rpn_class_loss: 0.0929 - rpn_bbox_loss: 5.2169 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 3.0684 - val_rpn_class_loss: 0.0161 - val_rpn_bbox_loss: 2.2684 - val_mrcnn_class_loss: 0.0037 - val_mrcnn_bbox_loss: 0.6533 - val_mrcnn_mask_loss: 0.1269\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 10s 9s/step - batch: 0.5000 - size: 1.0000 - loss: 4.1879 - rpn_class_loss: 0.0931 - rpn_bbox_loss: 2.0197 - mrcnn_class_loss: 0.0298 - mrcnn_bbox_loss: 1.3947 - mrcnn_mask_loss: 0.6505 - val_loss: 5.3744 - val_rpn_class_loss: 0.0189 - val_rpn_bbox_loss: 2.6522 - val_mrcnn_class_loss: 0.1202 - val_mrcnn_bbox_loss: 1.9379 - val_mrcnn_mask_loss: 0.6451\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 10s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 3.6359 - rpn_class_loss: 0.0817 - rpn_bbox_loss: 1.7521 - mrcnn_class_loss: 0.0378 - mrcnn_bbox_loss: 1.1240 - mrcnn_mask_loss: 0.6404 - val_loss: 4.1999 - val_rpn_class_loss: 0.0211 - val_rpn_bbox_loss: 3.4127 - val_mrcnn_class_loss: 0.0054 - val_mrcnn_bbox_loss: 0.6012 - val_mrcnn_mask_loss: 0.1595\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 10s 10s/step - batch: 0.5000 - size: 1.0000 - loss: 3.4886 - rpn_class_loss: 0.0650 - rpn_bbox_loss: 1.6372 - mrcnn_class_loss: 0.0090 - mrcnn_bbox_loss: 1.1396 - mrcnn_mask_loss: 0.6378 - val_loss: 5.2385 - val_rpn_class_loss: 0.0226 - val_rpn_bbox_loss: 2.5850 - val_mrcnn_class_loss: 0.0890 - val_mrcnn_bbox_loss: 1.8740 - val_mrcnn_mask_loss: 0.6679\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8156f82b-ecb6-40e3-b5a2-752268cbedef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
